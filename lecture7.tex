%Template
%Copyright (C) 2019  Patrick Diehl
%
%This program is free software: you can redistribute it and/or modify
%it under the terms of the GNU General Public License as published by
%the Free Software Foundation, either version 3 of the License, or
%(at your option) any later version.

%This program is distributed in the hope that it will be useful,
%but WITHOUT ANY WARRANTY; without even the implied warranty of
%MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
%GNU General Public License for more details.

%You should have received a copy of the GNU General Public License
%along with this program.  If not, see <http://www.gnu.org/licenses/>.
\documentclass[12pt,t]{beamer}

\beamertemplatenavigationsymbolsempty

% usepackage
%\usepackage{template/dbt}
\usepackage{listings}

\definecolor{comments}{RGB}{81,81,81}
\definecolor{keywords}{RGB}{255,0,90}

% lstlisting
\lstset{
    language=C,
    basicstyle=\footnotesize\ttfamily,
    keywordstyle=\color{keywords},
    showspaces=false,
    showstringspaces=false,
    commentstyle=\color{blue}\emph
    %frame=single,
    %rulecolor=\color{comments},
    %rulesepcolor=\color{comments},
    %backgroundcolor = \color{lightgray}
}

\usetheme{default}

\usepackage[
    type={CC},
    modifier={by-nc-nd},
    version={4.0},
]{doclicense} 

\usepackage{tikz}

\input{template/variables.tex}

% frame slide
\title{\coursename}
\subtitle{Lecture 7: Shared memory  parallelism}

%\author{\href{}{}}
%\institute {
%    \href{}{\tt \scriptsize \today}
%}
\date {
 \tiny \url{\courseurl}
\vspace{2cm}
\doclicenseThis  
  
}



\usepackage{ifxetex}

\ifxetex
\usepackage{fontspec}
\setmainfont{Raleway}
\fi

\begin{document} {
    \setbeamertemplate{footline}{}
    \frame {
        \titlepage
    }
}

\frame{

\tableofcontents

}

\AtBeginSection[]{
  \begin{frame}
  \vfill
  \centering
  \begin{beamercolorbox}[sep=8pt,center,shadow=true,rounded=true]{title}
    \usebeamerfont{title}\insertsectionhead\par%
  \end{beamercolorbox}
  \vfill
  \end{frame}
}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Reminder}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}{Lecture X}
\begin{block}{What you should know from last lecture}
\begin{itemize}
\item Lamba functions
\item Advanced loops
\end{itemize}
\end{block}
\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Shared memory parallelism}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{frame}{Definition of parallelism}

\begin{itemize}
\item We need multiple resources which can operate at the same time
\item We have to have more than one task that can be performed at the same time
\item We have to do multiple tasks on multiple resources the same time
\end{itemize}

\end{frame}

\begin{frame}{Amdahl's Law (Strong scaling)~\cite{amdahl1967validity}}



\begin{align*}
S = \frac{1}{(1-P) + \frac{P}{N}}
\end{align*}
where $S$ is the speed up, $P$ the proportion of parallel code, and $N$ the numbers of threads.

\begin{block}{Example}
A program took 20 hours using a single thread and only the part took one hour can be run in parallel, we will get $P=0.95$. So the theoretical speed up is $\frac{1}{(1-0.95)}=20$.
\end{block}
\begin{center}
\textcolor{blue}{Parallel computing with many threads is only beneficial for highly parallelizable programs.}
\end{center}

\end{frame}





\begin{frame}{}
\cite{el2005advanced,hager2010introduction}
\end{frame}



\begin{frame}{Uniform memory access (UMA)}

\begin{center}
\begin{tikzpicture}
%Threads
\draw (0,3) rectangle (.5,3.5) node[pos=.5] {1};
\draw (0.5,3) rectangle (1.0,3.5) node[pos=.5] {..};
\draw (1.,3) rectangle (1.5,3.5) node[pos=.5] {n};

\draw (2.5,3) rectangle (3.,3.5) node[pos=.5] {1};
\draw (3.,3) rectangle (3.5,3.5) node[pos=.5] {..};
\draw (3.5,3) rectangle (4,3.5) node[pos=.5] {n};

\draw (0.75,2.5) -- (0.75,3.);
\draw (3.25,2.5) -- (3.25,3.);

%BUS
\draw (0,1) rectangle (4,1.5) node[pos=.5] {Bus};


%CPU
\draw (0,2) rectangle (1.5,2.5) node[pos=.5] {CPU 1};
\draw (2.5,2) rectangle (4,2.5) node[pos=.5] {CPU 2};
\draw (0.75,2) -- (0.75,1.5);
\draw (3.25,2) -- (3.25,1.5);

%Memory
\draw (0,0) rectangle (4,0.5) node[pos=.5] {Memory};
\draw (0.75,.5) -- (0.75,1.);
\draw (3.25,.5) -- (3.25,1.);
\end{tikzpicture}
\end{center}

\begin{block}{Access times}
\begin{itemize}
\item Memory access times are the same
\end{itemize}
\end{block}

\end{frame}

\begin{frame}{Non-uniform memory access (NUMA)}


\begin{center}
\begin{tikzpicture}
%Threads
\draw (0,3) rectangle (.5,3.5) node[pos=.5] {1};
\draw (0.5,3) rectangle (1.0,3.5) node[pos=.5] {..};
\draw (1.,3) rectangle (1.5,3.5) node[pos=.5] {n};

\draw (2.5,3) rectangle (3.,3.5) node[pos=.5] {1};
\draw (3.,3) rectangle (3.5,3.5) node[pos=.5] {..};
\draw (3.5,3) rectangle (4,3.5) node[pos=.5] {n};

\draw (0.75,2.5) -- (0.75,3.);
\draw (3.25,2.5) -- (3.25,3.);

%BUS
\draw (0,1) rectangle (1.5,1.5) node[pos=.5] {Bus};
\draw (2.5,1) rectangle (4,1.5) node[pos=.5] {Bus};

%CPU
\draw (0,2) rectangle (1.5,2.5) node[pos=.5] {CPU 1};
\draw (2.5,2) rectangle (4,2.5) node[pos=.5] {CPU 2};
\draw (0.75,2) -- (0.75,1.5);
\draw (3.25,2) -- (3.25,1.5);

%Memory
\draw (0,0) rectangle (1.5,0.5) node[pos=.5] {Memory};
\draw (2.5,0) rectangle (4,0.5) node[pos=.5] {Memory};
\draw (0.75,.5) -- (0.75,1.);
\draw (3.25,.5) -- (3.25,1.);
\end{tikzpicture}
\end{center}

Access time to the memory depends on the memory location relative to the CPU.

\begin{block}{Access times}
\begin{itemize}
\item Local memory access is fast
\item Non-local memory access has some overhead
\end{itemize}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Parallel algorithms}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{frame}[fragile]{Parallel algorithms in C++ 17\footnote{\tiny\url{https://en.cppreference.com/w/cpp/experimental/parallelism}}}
\begin{itemize}
\item C++17 added support for parallel algorithms to the standard library, to help programs take advantage of parallel execution for improved performance.
\item Parallelized versions of 69 algorithms from \lstinline|<algorithm>|, \lstinline|<numeric>| and \lstinline|<memory>| are available. 
\end{itemize}

\begin{block}{Recently new feature!}
Only recently released compilers (gcc 9 and MSVC 19.14)\footnote{\tiny\url{https://en.cppreference.com/w/cpp/compiler_support}} implement these new features and some of them are still experimental.\\
\vspace{0.5cm}
Some special compiler flags are needed to use these features:

\begin{lstlisting}[language=bash]
g++ -std=c++1z -ltbb lecture7-loops.cpp 
\end{lstlisting}
\end{block}
\end{frame}

\begin{frame}[fragile]{Example: Accumulate}

\begin{lstlisting}
std::vector<int> nums(1000000,0);
\end{lstlisting}

\begin{block}{Sequential\footnote{\tiny\url{https://en.cppreference.com/w/cpp/algorithm/accumulate}}}
\begin{lstlisting}
auto result = std::accumulate(nums.begin(), 
                              nums.end(),
                              0.0);
\end{lstlisting}
\end{block}

\begin{block}{Parallel\footnote{\tiny\url{https://en.cppreference.com/w/cpp/experimental/reduce}}}
\begin{lstlisting}
auto result = std::reduce(
              std::execution::par,
              nums.begin(), nums.end());
\end{lstlisting}
\end{block}

Important: \lstinline|std::execution::par| from \lstinline|#include<execution>|\footnote{\tiny\url{https://en.cppreference.com/w/cpp/experimental/execution_policy_tag}}
\end{frame}


\begin{frame}[fragile]{Execution time}

\begin{block}{Time measurements}
\begin{lstlisting}[language=bash]
g++ -std=c++1z -ltbb lecture7-loops.cpp 
./a.out
std::accumulate result 0.000000 took 8164.458818 ms
std::reduce result 0.000000 took 584.451218 ms
\end{lstlisting}


\end{block}


\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Execution policies}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


\begin{frame}{Execution policies}

\begin{itemize}
\item \lstinline|std::execution::seq| \\
The algorithm is executed sequential, like \lstinline|std::accumulate| in the previous example and using only once thread.
\item \lstinline|std::execution::par| \\
The algorithm is executed in parallel and used multiple threads.
\item \lstinline| std::execution::par_unseq| \\
The algorithm is executed in parallel and vectorization is used.
\end{itemize}
Note we will not cover vectorization in this course. \\
\vspace{0.5cm}
Fore more details: CppCon 2016: Bryce Adelstein Lelbach â€œThe C++17 Parallel Algorithms Library and Beyond"\footnote{\tiny{\url{https://www.youtube.com/watch?v=Vck6kzWjY88}}}
\end{frame}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Be aware of: Data races and Dead looks}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{frame}{Be aware of}

\begin{center}
With great power comes great responsibility!

\end{center}


\begin{block}{You are responsible}
When using parallel execution policy, it is the programmer's responsibility to avoid
\begin{itemize}
\item data races
\item race conditions
\item deadlocks
\end{itemize} 
\end{block}

\end{frame}

\begin{frame}[fragile]{Data race}

\begin{lstlisting}
//Compute the sum of the array a in parallel
int a[] = {0,1};
int sum = 0;
std::for_each(std::execution::par, 
              std::begin(a), 
              std::end(a), [&](int i) {
  sum += a[i]; // Error: Data race
});
\end{lstlisting}

\begin{block}{Data race:}
A data race exists when multithreaded (or otherwise parallel) code that would access a shared resource could do so in such a way as to cause unexpected results.
\end{block}

\end{frame}

\begin{frame}[fragile]{Solution I: data races}

\begin{block}{\lstinline|std::atomic|\footnote{\tiny\url{https://en.cppreference.com/w/cpp/atomic/atomic}}}
\begin{lstlisting}
//Compute the sum of the array a in parallel
int a[] = {0,1};
std::atomic<int> sum{0};
std::for_each(std::execution::par, 
              std::begin(a), 
              std::end(a), [&](int i) {
  sum += a[i]; 
});
\end{lstlisting}
\end{block}

The atomic library\footnote{\tiny\url{https://en.cppreference.com/w/cpp/atomic}} provides components for fine-grained atomic operations allowing for lockless concurrent programming. Each atomic operation is indivisible with regards to any other atomic operation that involves the same object. Atomic objects are free of data races. 
\end{frame}


\begin{frame}[fragile]{Solution 2: data races}
\begin{block}{\lstinline|std::mutex|\footnote{\tiny\url{https://en.cppreference.com/w/cpp/thread/mutex}}}
\begin{lstlisting}
//Compute the sum of the array a in parallel
int a[] = {0,1};
int sum = 0;
std::mutex m;
std::for_each(std::execution::par, 
              std::begin(a), 
              std::end(a), [&](int i) {
  m.lock();
  sum += a[i];
  m.unlock(); 
});
\end{lstlisting}
\end{block}
The mutex class is a synchronization primitive that can be used to protect shared data from being simultaneously accessed by multiple threads. 
\end{frame}


\begin{frame}[fragile]{Race condition}

\begin{lstlisting}

if (x == 5)  // Checking x
{
   // Different thread could change x 
      
   y = x * 2; // Using x
}
// It is not sure if y is 10 or any other value.
\end{lstlisting}

\begin{block}{Race condition}
A check of a shared variable within a parallel execution and another thread could change this variable before it is used.
\end{block}

\end{frame}

\begin{frame}[fragile]{Solution: Race condition}


\begin{lstlisting}
std::mutex m;

m.lock();
if (x == 5)  // Checking x
{
   // Different thread could change x 
      
   y = x * 2; // Using x
}
m.unlock();
// Now it is sure that y will be 10
\end{lstlisting}

\begin{block}{Race condition}
A check of a shared variable within a parallel execution and another thread could change this variable before it is used.
\end{block}


\end{frame}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Summary}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}{Summary}
\begin{block}{After this lecture, you should know}
\begin{itemize}
\item Shared memory parallelism
\item Parallel algorithms
\item Execution policies
\item Mutex
\end{itemize}
\end{block}

\begin{block}{Further reading:}
C++ Lecture 3 - Modern Paralization Techniques\footnote{\tiny\url{https://www.youtube.com/watch?v=1DUW5Qw3eck}}: OpenMP for shared memory parallelism and the Message Passing Interface for distributed memory parallelism. Note that HPX which will we cover after the midterm is introduced there.
\end{block}

\end{frame}




%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{References}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{frame}[t, allowframebreaks]
\frametitle{References}
\bibliographystyle{plain}
\bibliography{bib}
\end{frame}


\end{document}